{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>IRIS TRAINING</h1><center>\n",
    "\n",
    "> A model to classify flowers based on the famous Iris flower dataset.\n",
    "\n",
    "The dataset used here is one of the simplest Machine Learning study cases:\n",
    "[**Iris**](https://en.wikipedia.org/wiki/Iris_flower_data_set).\n",
    "\n",
    "We've separated it in two files: one for the features (flower measures) and one for the labels (flower species). The idea is handle tabular datasets structured in multiple files.\n",
    "    \n",
    "The original Fisher dataset contains a set of 150 records under five attributes - sepal length, sepal width, petal length, petal width and species:\n",
    "      \n",
    "| sepal length | sepal width | petal length | petal width |   species |\n",
    "|      :-:     |     :-:     |      :-:     |     :-:     |     :-:   |\n",
    "|      5.1     |     3.5     |      1.4     |     0.2     | I. setosa |\n",
    "|      4.9     |     3.0     |      1.4     |     0.2     | I. setosa |\n",
    "|      4.7     |     3.2     |      1.3     |     0.2     | I. setosa |\n",
    "|      4.6     |     3.1     |      1.5     |     0.2     | I. setosa |\n",
    "|      5.0     |     3.6     |      1.4     |     0.3     | I. setosa |\n",
    "|      5.4     |     3.9     |      1.7     |     0.4     | I. setosa |\n",
    "|      4.6     |     3.4     |      1.4     |     0.3     | I. setosa |\n",
    "|      5.0     |     3.4     |      1.5     |     0.2     | I. setosa |\n",
    "|      4.4     |     2.9     |      1.4     |     0.2     | I. setosa |\n",
    "|      4.9     |     3.1     |      1.5     |     0.1     | I. setosa |\n",
    "|      ...     |     ...     |      ...     |     ...     |    ...    |\n",
    "    \n",
    "Based on this dataset we can split it into two pieces. One for the flower measures, and the other for the corresponding species. Further ahead we are going to name this datasets as:\n",
    "> **entries**: flower measurements dataset\n",
    "    \n",
    ">**classes**: the corresponding classification for the given measures entries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation and Classification Methods\n",
    "\n",
    "Another important aspect regarding Machine Learning is the selection of \"training\" and \"test\" sets, a proper allocation of datasets for these two jobs can deeply impact the accuracy and performance of the model. Here, we are going to use a Stratified K Fold method:\n",
    "\n",
    "[Stratified K Fold Cross Validation](https://www.geeksforgeeks.org/stratified-k-fold-cross-validation/)\n",
    "\n",
    "As our classification method, we are going to use the Support Vector Machine:\n",
    "\n",
    "[Wikipedia](https://en.wikipedia.org/wiki/Support_vector_machine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM Params\n",
    "gamma = 0.1\n",
    "kernel = 'linear'\n",
    "\n",
    "# K Fold Params\n",
    "n_folds = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"gamma\": gamma, \"kernel\": kernel, \"n_folds\": n_folds}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the datasets\n",
    "\n",
    "The Iris dataset is so popular that you can load them in-memory straight from the scikit-learn package:\n",
    "```python\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "iris\n",
    "```\n",
    "\n",
    "This will load all the information regarding the dataset into a `dict()`\n",
    "\n",
    "As mentioned before we will be working with two datasets, `measures.csv` and `species.csv`. It was a particular option to load the datasets from local files instead of loading them from the scikit-learn package. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entries = np.genfromtxt('datasets/measures.csv', delimiter=',')\n",
    "classes = np.genfromtxt('datasets/species.csv', dtype=str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the estimator and folding strategy:\n",
    "\n",
    "Now it is time to create our estimator and define our cross validation datasets using the K Fold method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(kernel=kernel, gamma=gamma)\n",
    "fold = StratifiedKFold(n_splits=n_folds,\n",
    "                       shuffle=True,\n",
    "                       random_state=np.random.RandomState(19))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAINING\n",
    "\n",
    "Let's initialize the training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = cross_val_score(estimator=clf,\n",
    "                        X=entries,\n",
    "                        y=classes,\n",
    "                        cv=fold,\n",
    "                        n_jobs=-1)\n",
    "\n",
    "metrics = dict(score_avg=score.mean(),\n",
    "               score_var=np.sqrt(score.var()))\n",
    "\n",
    "clf.fit(entries, classes) # definitive training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PUBLISH "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(clf, 'clf.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
